---
title: "Estimation de la tendance-cycle avec des méthodes robustes aux points atypiques"
format: 
  html:
    fig-width: 9
    toc-depth: 3
    include-before-body: template/preambule.html
    output-file: index
  pdf:
    include-in-header: template/preambule.tex
    keep-tex: true
    classoption: french
    cite-method: biblatex
    pdf-engine: pdflatex
    papersize: A4
    fig-width: 7.5
    toc: false # to include abstract first
    fig-pos: 'H'
execute: 
  cache: true
lang: fr
echo: false
toc: true
tbl-cap-location: top
fig-cap-location: top
bibliography: biblio.bib
# csl: chicago-author-date.csl
---

```{r}
#| include: false
library(rjd3filters)
library(ggplot2)
library(patchwork)
source("../0-functions.R", local = knitr::knit_global())
source("../0-functions-plot.R", local = knitr::knit_global())
lc_f <- lp_filter()
robust_ff <- readRDS("../data/robust_ff.rds")
y_as_plot <- FALSE
add_y <- FALSE
apply_consistent_y_lims <- function(this_plot){
    num_plots <- length(this_plot$layers)
    y_lims <- lapply(1:num_plots, function(x) ggplot_build(this_plot[[x]])$layout$panel_scales_y[[1]]$range$range)
    min_y <- min(unlist(y_lims))
    max_y <- max(unlist(y_lims))
    this_plot & coord_cartesian(ylim = c(min_y, max_y))
}
```


# Introduction

L'analyse du cycle économique, et en particulier la détection rapide des points de retournement d'une série, est un sujet de première importance dans l'analyse de la conjoncture économique. 
Pour cela, les indicateurs économiques sont généralement corrigés des variations saisonnières.
Toutefois, afin d'améliorer leur lisibilité, il peut être nécessaire d'effectuer un lissage supplémentaire afin de réduire le bruit, et ainsi analyser la composante tendance-cycle.
Par construction, les méthodes d'extraction de tendance-cycle sont étroitement liées aux méthodes de désaisonnalisation.
En effet, afin d'estimer la composante saisonnière, les algorithmes de désaisonnalisation estiment préalablement une composante tendance-cycle.
Ainsi, même si les méthodes d'extraction de tendance-cycle sont généralement appliquées sur des séries corrigées des variations saisonnières, l'estimation de ces séries dépend également également des méthodes d'estimation de la tendance-cycle.

Les moyennes mobiles, ou les filtres linéaires, sont omniprésents dans les méthodes d'extraction du cycle économique et d'ajustement saisonnier^[
Une moyenne mobile est une méthode statistique qui consiste à appliquer une moyenne pondérée glissante à une série temporelle : à chaque date $t$ on calcule une moyenne pondérée de $p$ points passés et $q$ points futurs où $p,q\geq0$ dépend de la moyenne mobile.
]. 
Ainsi, la méthode de désaisonnalisation X-13ARIMA-SEATS utilise des moyennes mobiles de Henderson et des moyennes mobiles composites pour estimer les principales composantes d'une série chronologique. 
Au centre de la série, des filtres symétriques sont appliqués. 
Pour l'extraction de la tendance-cycle, le filtre symétrique le plus connu est celui de @henderson1916note, notamment utilisé dans l'algorithme de désaisonnalisation X-13ARIMA. 

Toutefois, ces moyennes mobiles, comme tout opérateur linéaire, sont sensibles à la présence de points atypiques.
L'application directe des méthodes peut donc conduire à des estimations biaisées, du fait de leur présence, alors que les méthodes de désaisonnalisation (comme la méthode X-13ARIMA) ont un module de correction des points atypiques.

D'autre part, les moyennes mobiles étant des opérateurs linéaires, ils sont sensibles à la présence de points atypiques.
L'application directe des méthodes peut donc conduire à des estimations biaisées, du fait de leur présence, alors que les méthodes de désaisonnalisation (comme la méthode X-13ARIMA) ont un module de correction des points atypiques.

<!-- Par ailleurs, comme notamment montré par @dagum1996new, le filtre symétrique final utilisé par X-13ARIMA pour extraire la tendance-cycle (et donc celui indirectement utilisé lorsqu'on applique les méthodes sur les séries désaisonnalisées) laisse passer environ 72 % des cycles de 9 ou 10 mois (généralement associés à du bruit plutôt qu'à la tendance-cycle). -->
<!-- Les filtres asymétriques finaux amplifient même les cycles de 9 ou 10 mois. -->
<!-- Cela peut avoir pour conséquence l'introduction d'ondulations indésirables, c'est-à-dire la détection de faux points de retournement. -->
<!-- Ce problème est réduit par la correction des points atypiques (ces cycles étant considérés comme de l'irrégulier).  -->
<!-- C'est ainsi que le *Nonlinear Dagum Filter* (NLDF) a été développé et consiste à : -->

<!-- a. appliquer l'algorithme de correction des points atypiques de X-13ARIMA sur la série désaisonnalisée, puis de la prolonger par un modèle ARIMA ; -->

<!-- b. effectuer une nouvelle correction des points atypiques en utilisant un seuil bien plus strict et appliquer ensuite le filtre symétrique de 13 termes.  -->
<!-- En supposant une distribution normale cela revient à modifier 48 % des valeurs de l'irrégulier.    -->

<!-- Les *cascade linear filter* (CLF), notamment étudiés dans @dagumBianconcini2023, correspondent à une approximation des NLDF en utilisant un filtre de 13 termes et lorsque les prévisions sont obtenus à partir d'un modèle ARIMA(0,1,1) où $\theta=0,40.$ -->

<!-- Une piste d'étude serait alors d'étudier plus précisément l'effet des points atypiques sur l'estimation de la tendance-cycle et la détection des points de retournement, mais aussi d'explorer de nouveaux types de filtres asymétriques fondés sur des méthodes robustes (comme les régressions locales robustes, les médianes mobiles, etc.).  -->

<!-- En revanche, pour les estimations en temps réel, en raison de l'absence d'observations futures, toutes ces méthodes doivent s'appuyer sur des filtres asymétriques pour estimer les points les plus récents.  -->
<!-- Par exemple, même si X-13ARIMA-SEATS applique des moyennes symétriques aux prévisions obtenues à partir d'un modèle ARIMA, cela revient à appliquer des filtres asymétriques en fin de série, car les valeurs prédites sont des combinaisons linéaires de valeurs passées.  -->

<!-- Si ces moyennes mobiles asymétriques ont de bonnes propriétés concernant la taille des révisions futures induites par le processus de lissage^[Voir par exemple @pierce1980SA.], elles induisent également, par construction, des déphasages qui retardent en général la détection en temps réel des points de retournement. -->


# Méthodes utilisées

## Méthodes robustes


$$
y_{t+i}=\mu_t+\beta_ti+\varepsilon_{t,i}\text{ et }
r_{t+i}=y_{t+i}-\hat\mu_t-\hat\beta_ti
$$

- Médiane mobile :

$$
\hat\mu_t=\underset{i=-m,\dots,m}{\med}y_{t+i}
$$

- Least Median of Squares regression (LMS)
$$
(\hat\mu_t,\beta_t)=\underset{\hat\mu_t,\beta_t}{\argmin}\left\{ \underset{i=-m,\dots,m}{\med}r^2_{t+i} \right\}
$$

- Least Trimmed Squares regression (LTS)
$$
(\hat\mu_t,\hat\beta_t)=\underset{\hat\mu_t,\beta_t}{\argmin}\left\{ \sum_{i=-m}^m r^2_{t+i} \right\}
$$

- Repeated Median regression (RM)
$$
\hat{\beta}_{t}=\underset{i=1,\dots,n}{\med}\left\{ \underset{i\ne j}{\med}\frac{y_{t+i}-y_{t+j}}{i-j} \right\}
$$
et 
$$
\hat\mu_t=\underset{i=1,\dots,n}{\med}\left\{ y_{t+i}-i\hat{\beta}_{t} \right\}
$$
- Least Quartile Difference regression (LQD)

- Deepest Regression (DR)

## Moyennes mobiles linéaires

Moyennes mobiles classiques peuvent être obtenues par analogie avec la régression polynomiale locale
$$
\forall j\in\{ -h,-h+1,\dots, h\} : y_{t+j}=\underbrace{\sum_{i=0}^{d}\beta_{i}j^{i}}_{m_{t+j}}+\varepsilon_{t+j}
$$

Estimation en utilisant les WLS avec *noyaux*: $\hat{\beta}=(X'KX)^{1}X'Ky$ et
$$
\hat{TC}_{t}=\hat\beta_0=w'y=\sum_{j=-h}^{h}w_{j}y_{t-j}
$$
En ajoutant un régresseur $x_t$ on peut donc obtenir une nouvelle moyenne mobile donc l'estimation de $\beta_0$ prendrait en compte l'effet modélisé par $x_t$
$$
y_{t+j}=\sum_{i=0}^{d}\beta_{i}j^{i} + \gamma x_{t+j}+\varepsilon_{t+j}
$$

Deux cas sont ici étudiés :

- Points atypiques additifs (AO) : un choc soudain à une certaine date puis un retour à la normal.
Si le choc est à la date $t_0$ le régresseur utilisé est alors $x_t=1_{t=t_0}$.

- Rupture en niveau (LS) : un changement de niveau à une certaine date.
Si le choc est à la date $t_0$ le régresseur utilisé est alors $x_t=-1_{t< t_0}$ pour l'estimation de $TC_t$ avec $t\leq t_0$ et $x_t=1_{t\geq t_0}$ sinon.

Pour le cas asymétrique, @proietti2008 proposent une méthode générale pour construire les filtres asymétriques qui permet de faire un compromis biais-variance.
Il s'agit d'une généralisation des filtres asymétriques de @musgrave1964set (utilisés dans l'algorithme de désaisonnalisation X-13ARIMA).

On modélise ici la série initiale par :
$$
\boldsymbol y=\boldsymbol U\boldsymbol \gamma+\boldsymbol Z\boldsymbol \delta+\boldsymbol \varepsilon,\quad
\boldsymbol \varepsilon\sim\mathcal{N}(\boldsymbol 0,\boldsymbol D).
$${#eq-lpgeneralmodel}
où $[\boldsymbol U,\boldsymbol Z]$ est de rang plein et forme un sous-ensemble des colonnes de $\boldsymbol X$.
L'objectif est de trouver un filtre $\boldsymbol v$ qui minimise l'erreur quadratique moyenne de révision (au filtre symétrique $\boldsymbol \theta$) sous certaines contraintes.
Ces contraintes sont représentées par la matrice $\boldsymbol U=\begin{pmatrix}\boldsymbol U_{p}'&\boldsymbol U_{f}'\end{pmatrix}'$ : $\boldsymbol U_p'\boldsymbol v=\boldsymbol U'\boldsymbol \theta$ (avec $\boldsymbol U_p$ la matrice $(h+q+1)\times (d+1)$ qui contient les observations de la matrice $\boldsymbol U$ connues lors de l'estimation par le filtre asymétrique).
C'est ce qui est implémenté dans la fonction `rjd3filters::mmsre_filter()`.

Lorsque $\boldsymbol U=\boldsymbol X$, la contrainte équivaut à préserver les polynômes de degré $d$ : on retrouve les filtres directs symétriques avec $\boldsymbol D=\boldsymbol K^{-1}$.

Lorsque $\boldsymbol U$ correspond aux $d^*+1$ premières colonnes de $\boldsymbol X$, $d^*<d$, la contrainte consiste à reproduire des tendances polynomiales de degré $d^*$.
Cela introduit du biais mais réduit la variance. 
Le filtre de Musgrave se retrouve en modélisant $y_t$ linéaire ($d=1$) et $v$ préserve les constantes ($d^*=0$) et en prenant le filtre d'Henderson comme filtre symétrique.
Les filtres asymétriques robustes sont construits en ajoutant un régresseur supplémentaire à $\boldsymbol U$ (estimation sans biais de l'outlier) et en utilisant comme filtre symétrique celui construit en utilisant le même régresseur.

# Résultats

## Additive outlier (A0)

### IPI voitures

#### Août 1998


```{r}
res <- readRDS(file.path("..", "results", "AO", "ipi_voitures98.RDS"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est <- lapply(graph_est,function(p){
	p$CLF <- NULL
	p
})
graph_y <- plot_y(res)
graph_ci <- lapply(
	res$out, plot_confint,
	data = res,
	default_filter = lc_f,
	robust_f = robust_ff[["ao"]])
```


```{r}
#| label: fig-ipi_voitures98-out1-y
#| fig.cap: "Série brute"
graph_y[[1]]
```

```{r}
#| label: fig-ipi_voitures98-out1-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
#| 
patchwork::wrap_plots(graph_est[[1]], ncol = 3) 
```


```{r}
#| label: fig-ipi_voitures98-out1-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci[[1]], ncol = 3)
```

#### Août 1999


```{r}
#| label: fig-ipi_voitures98-out2-y
#| fig.cap: "Série brute"
graph_y[[2]]
```

```{r}
#| label: fig-ipi_voitures98-out2-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
#| 
patchwork::wrap_plots(graph_est[[2]], ncol = 3)
```


```{r}
#| label: fig-ipi_voitures98-out2-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci[[2]], ncol = 3)
```


#### 2004


```{r}
res <- readRDS(file.path("..", "results", "AO", "ipi_voitures2004.RDS"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est$CLF <- NULL
graph_y <- plot_y(res)
graph_ci <- plot_confint(
	res,
	default_filter = lc_f,
	robust_f = robust_ff[["ao"]])
```

```{r}
#| label: fig-ipi_voitures2004-y
#| fig.cap: "Série brute"
graph_y
```

```{r}
#| label: fig-ipi_voitures2004-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
#| 
patchwork::wrap_plots(graph_est, ncol = 3)
```


```{r}
#| label: fig-ipi_voitures2004-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci, ncol = 3)
```

## Level shift (LS)

### IPI petrole brut

```{r}
res <- readRDS(file.path("..", "results", "LS", "ipi_petrole_brut10.RDS"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est$CLF <- NULL
graph_y <- plot_y(res)
graph_ci <- plot_confint(
	res,
	default_filter = lc_f,
	robust_f = robust_ff[["ls"]])
```

```{r}
#| label: fig-ipi_petrole_brut10-y
#| fig.cap: "Série brute"
graph_y
```

```{r}
#| label: fig-ipi_petrole_brut10-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
#| 
patchwork::wrap_plots(graph_est, ncol = 3)
```


```{r}
#| label: fig-ipi_petrole_brut10-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci, ncol = 3)
```



## Deux LS

### Retailx

```{r}
res <- readRDS(file.path("..", "results", "LSLS", "retailx2008.RDS"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est$CLF <- NULL
graph_y <- plot_y(res)
graph_ci <- plot_confint(
	res,
	default_filter = lc_f,
	robust_f = robust_ff[["lsls"]])
```

```{r}
#| label: fig-retailx2008-y
#| fig.cap: "Série brute"
graph_y
```

```{r}
#| label: fig-retailx2008-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
#| 
patchwork::wrap_plots(graph_est, ncol = 3)
```


```{r}
#| label: fig-retailx2008-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci, ncol = 3)
```


## AO puis LS

### Immatriculation de véhicules neufs

```{r}
res <- readRDS(file.path("..", "results", "AOLS", "immat2018.RDS"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est$CLF <- NULL
graph_y <- plot_y(res)
graph_ci <- plot_confint(
	res,
	default_filter = lc_f,
	robust_f = robust_ff[["aols"]])
```

```{r}
#| label: fig-imat2018-y
#| fig.cap: "Série brute"
graph_y
```



```{r}
#| label: fig-imat2018-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
#| 
patchwork::wrap_plots(graph_est, ncol = 3)
```


```{r}
#| label: fig-imat2018-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci, ncol = 3)
```

## Point de retournement

### Retailx

```{r}
res <- readRDS(file.path("..", "results", "AO", "retailx2007.rds"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est$CLF <- NULL
graph_y <- plot_y(res)
graph_ci <- plot_confint(
	res,
	default_filter = lc_f,
	robust_f = robust_ff[["ao"]])
```

```{r}
#| label: fig-retailx2007-y
#| fig.cap: "Série brute"
graph_y
```



```{r}
#| label: fig-retailx2007-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
patchwork::wrap_plots(graph_est, ncol = 3)
```


```{r}
#| label: fig-retailx2007-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci, ncol = 3)
```

### ce160v

```{r}
res <- readRDS(file.path("..", "results", "AO", "ce160v2001.rds"))
graph_est <- get_all_plots(res, y_as_plot = y_as_plot, add_y = add_y)
graph_est$CLF <- NULL
graph_y <- plot_y(res)
graph_ci <- plot_confint(
	res,
	default_filter = lc_f,
	robust_f = robust_ff[["ao"]])
```

```{r}
#| label: fig-ce160v2001-y
#| fig.cap: "Série brute"
graph_y
```



```{r}
#| label: fig-ce160v2001-est
#| fig.cap: "Estimations en temps réel de la tendance-cycle"
#| fig-height: 8
patchwork::wrap_plots(graph_est, ncol = 3)
```


```{r}
#| label: fig-ce160v2001-ci
#| fig.cap: "Intervalles de confiance pour les filtres de musgrave"
#| fig-width: 9
patchwork::wrap_plots(graph_ci, ncol = 3)
```

# Annexe

## Construction d'intervalles de confiance

Soit $\theta = \begin{pmatrix}\theta_{-p},\dots,\theta_f\end{pmatrix}$ une moyenne mobile.
Si $\theta$ permet d'avoir un estimateur sans biais de la tendance-cycle $TC_t$ ($\mathbb E[\hat{TC}_t]=TC_t$ avec $\hat{TC}_t = \sum_{i=-p}^p\theta_iy_i$), alors un intervalle de confiance peut être calculé à partir de la formule :
$$
I_t=\left[\hat{TC}_t - q_{\alpha}\sqrt{\hat \sigma^2}\sqrt{\sum_{i=-p}^{f}\theta_i^2};
 \hat{TC}_t  + q_{\alpha}\sqrt{\hat \sigma^2}\sqrt{\sum_{i=-p}^{f}\theta_i^2}\right]
$$
Indeed, as shown by @Loader1999, the variance $\sigma^2$ can be estimating using the normalized residual sum of squares:
$$
\hat\sigma^2=\frac{1}{(n-p-f)-2\nu_1+\nu_2}\sum_{t=p+1}^{n-f}(y_t-\widehat{TC}_t)^2.
$$
With $\theta$ only $n-p-f$ observations can be used to estimate $\sigma^2$.
$\nu_1$ and $\nu_2$ are two definitions of degrees of freedom of a local fit (generalization of the number of parameters of a parametric model).
In the case of local polynomial smoothing, they can be linked to the coefficient of the associated filter: $\nu_1 = (n-p-f)\theta_0$ (number of observations multiplied by the central coefficient of the moving average) and $\nu_2 = (n-p-f)\sum_{i=-h}^{h} \theta_i^2$ (number of observations multiplied by the sum of squares of coefficients of the moving average).
Thus, the variance can be estimated by:
$$
\hat\sigma^2=\frac{1}{n-p-f}\sum_{t=p+1}^{n-f}\frac{(y_t-\widehat{TC}_t)^2}{1-2\theta_0^2+\sum_{i=-p}^{f} \theta_i^2}.
$$
This is implemented in the function `rjd3filters::var_estimator()`.
This estimator assumes that $\widehat{TC}_t$ is unbiased, so variance estimates intervals are usually computed at small bandwidths ($h$).
In this paper we study monthly series with small bandwidth ($h=6$), and the variance is estimated using local polynomial of degree 3 (Henderson filter), the biased of $\widehat{TC}_t$ is thus already small and using smaller bandwidths have almost no impact on the estimates (see supplemental materials).


## Moyennes mobiles utilisées


```{r}
#| label: fig-mm-musgrave
#| fig.cap: "Henderson et filtre de musgrave"
ggdemetra3::ggplot_coef(lp_filter(), q= 0:6)
```

```{r}
#| label: fig-clf
#| fig.cap: "Cascade linear filter"
ggdemetra3::ggplot_coef(CLF, q= 0:6)
```

```{r}
#| label: fig-clfnn
#| fig.cap: "Cascade linear filter et cut and normalize"
ggdemetra3::ggplot_coef(CLF_CN, q= 0:6)
```

```{r}
#| label: fig-robust-ao
#| fig.cap: "Filtre robuste AO présent à la dernière date"
ggdemetra3::ggplot_coef(robust_ff$ao$t0, q= 0:7)
```

```{r}
#| label: fig-robust-aols
#| fig.cap: "Filtre robuste AO puis LS présent à la dernière date"
ggdemetra3::ggplot_coef(robust_ff$aols$`t-1`, q= 0:7)
```

```{r}
#| label: fig-robust-ls
#| fig.cap: "Filtre robuste LS présent à la dernière date"
ggdemetra3::ggplot_coef(robust_ff$ls$t0, q= 0:7)
```

```{r}
#| label: fig-robust-lsls
#| fig.cap: "Filtre robuste deux LS présents aux deux dernières dates"
ggdemetra3::ggplot_coef(robust_ff$lsls$`t-1`, q= 0:7)
```
